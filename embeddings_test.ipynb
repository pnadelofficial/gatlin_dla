{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FlagEmbedding import FlagModel\n",
    "\n",
    "model = FlagModel(\"BAAI/bge-large-en\", \n",
    "    query_instruction_for_retrieval=\"Represent this sentence for searching relevant passages: \"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = ['conflicting', 'inexperience', 'assumption', 'appreciation', 'genetics', 'client relations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "consol_pre = pd.read_csv('./data/pre_consolidated.csv')\n",
    "sep_pre = consol_pre[['ID'] + list(consol_pre.columns[14:-2])]\n",
    "sep_pre_col_names = ['ID', 'Q14', 'Q15', 'Q16', 'Q18', 'Q19', 'Q20', 'Q21', 'Q22', 'Q23', 'Q24', 'Q25']\n",
    "sep_pre.columns = sep_pre_col_names\n",
    "\n",
    "consol_post = pd.read_csv('./data/post_consolidated.csv')\n",
    "sep_post = consol_post[['ID'] + list(consol_post.columns[14:-3])]\n",
    "sep_post_col_names = ['ID', 'Q15', 'Q16', 'Q17', 'Q18', 'Q19', 'Q20', 'Q21', 'Q22', 'Q23', 'Q24', 'Q25', 'Q26']\n",
    "sep_post.columns = sep_post_col_names\n",
    "\n",
    "pre_fr = sep_pre[['ID', 'Q20', 'Q21', 'Q22', 'Q23', 'Q24', 'Q25']]\n",
    "post_fr = sep_post[['ID', 'Q21', 'Q22', 'Q23', 'Q24', 'Q25', 'Q26']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import sent_tokenize\n",
    "\n",
    "all_responses = []\n",
    "for col in pre_fr.columns[1:]:\n",
    "    pre_sent = pre_fr[col].apply(sent_tokenize)\n",
    "    pre_sent = pre_sent.explode()\n",
    "    for fr in list(pre_sent):\n",
    "        all_responses.append(fr)\n",
    "\n",
    "for col in post_fr.columns[1:]:\n",
    "    post_sent = post_fr[col].apply(sent_tokenize)\n",
    "    post_sent = post_sent.explode()\n",
    "    for fr in list(post_sent):\n",
    "        all_responses.append(fr)\n",
    "\n",
    "len(all_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_embeddings = model.encode_queries(queries)\n",
    "p_embeddings = model.encode(all_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = q_embeddings @ p_embeddings.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 253)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 97,  18,  99, 132, 176, 164, 217,  91,  14, 221, 212, 175, 229,\n",
       "       210,  81,   3,  15, 153, 209,  22,  10, 214,  89, 103,  82,  74,\n",
       "         8, 124,  96, 219, 231,  70,  44, 136, 206, 213,  76, 101, 117,\n",
       "       208, 222,  58, 104,   9, 137,  84,  67, 114,  66,  71, 100,  93,\n",
       "         6, 220,  75,  85,  24,  29,  94, 139, 249, 190,  51,  83, 216,\n",
       "       196, 226, 224,  79,  12,  80, 178,  88,  60, 129,  57, 228,  39,\n",
       "       199, 105, 166, 133,   1,  65,   7, 111, 102,  95, 161, 113,   5,\n",
       "       120, 223, 252, 211, 251, 189,  64,  77, 198,  68, 118, 119,  26,\n",
       "       141,  78, 145, 225, 233, 154, 138, 148,  72, 246, 108, 131, 151,\n",
       "        69,  54,  20, 165, 245, 243, 110, 204,  28, 184, 215,  27,  53,\n",
       "       185, 134,  63, 116,  21, 128, 112,  32, 130,  92,  56,  98, 168,\n",
       "        45, 240, 201, 163, 232, 160, 182, 158, 187, 140, 239,  73,  90,\n",
       "       230, 152, 146, 107,  17, 244,   0, 135,  31, 156, 248,  16, 106,\n",
       "       247, 194, 173,  42, 162,  52, 126, 121,   2, 237,  40,   4, 144,\n",
       "       147,  59,  19, 200, 202,  23,  13, 241, 115, 218, 159,  30,  55,\n",
       "        86, 171,  47,  25,  38, 197,  43, 181, 207, 127, 143, 179, 122,\n",
       "        46,  35, 149, 203, 191,  41, 238,  33, 125, 167, 236, 142,  48,\n",
       "       157, 192, 155,  34,  87, 195, 250, 169, 180, 183,  61, 174, 170,\n",
       "        36, 205, 227, 123, 186, 172, 188, 235, 242, 109,  11, 177,  50,\n",
       "       193,  37,  49, 234,  62, 150])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[0].argsort()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I think the most predominate belief that was challenged is that not all breeders are the same.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_responses[132]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('dla')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26c8c46588d5b2acb06918ee9447e16dc8aeea43f0cbd838ad3eb4fc9c314363"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
