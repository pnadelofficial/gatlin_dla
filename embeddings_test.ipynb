{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FlagEmbedding import FlagModel\n",
    "\n",
    "model = FlagModel(\"BAAI/bge-large-en\", \n",
    "    query_instruction_for_retrieval=\"Represent this sentence for searching relevant passages: \"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = ['conflicting', 'inexperience', 'assumption', 'appreciation', 'genetics', 'client relations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "consol_pre = pd.read_csv('./data/pre_consolidated.csv')\n",
    "sep_pre = consol_pre[['ID'] + list(consol_pre.columns[14:-2])]\n",
    "sep_pre_col_names = ['ID', 'Q14', 'Q15', 'Q16', 'Q18', 'Q19', 'Q20', 'Q21', 'Q22', 'Q23', 'Q24', 'Q25']\n",
    "sep_pre.columns = sep_pre_col_names\n",
    "\n",
    "consol_post = pd.read_csv('./data/post_consolidated.csv')\n",
    "sep_post = consol_post[['ID'] + list(consol_post.columns[14:-3])]\n",
    "sep_post_col_names = ['ID', 'Q15', 'Q16', 'Q17', 'Q18', 'Q19', 'Q20', 'Q21', 'Q22', 'Q23', 'Q24', 'Q25', 'Q26']\n",
    "sep_post.columns = sep_post_col_names\n",
    "\n",
    "pre_fr = sep_pre[['ID', 'Q20', 'Q21', 'Q22', 'Q23', 'Q24', 'Q25']]\n",
    "post_fr = sep_post[['ID', 'Q21', 'Q22', 'Q23', 'Q24', 'Q25', 'Q26']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import sent_tokenize\n",
    "\n",
    "all_responses = []\n",
    "for col in pre_fr.columns[1:]:\n",
    "    pre_sent = pre_fr[col].apply(sent_tokenize)\n",
    "    pre_sent = pre_sent.explode()\n",
    "    for fr in list(pre_sent):\n",
    "        all_responses.append(fr)\n",
    "\n",
    "for col in post_fr.columns[1:]:\n",
    "    post_sent = post_fr[col].apply(sent_tokenize)\n",
    "    post_sent = post_sent.explode()\n",
    "    for fr in list(post_sent):\n",
    "        all_responses.append(fr)\n",
    "\n",
    "len(all_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_embeddings = model.encode_queries(queries)\n",
    "p_embeddings = model.encode(all_responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = q_embeddings @ p_embeddings.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 253)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 68,  74, 217, 229, 170,  51,  48, 206, 112,  85, 214,  66,  97,\n",
       "       196, 209, 189, 228,   4,  94,  99, 220, 225, 208,  67,  11, 103,\n",
       "       105, 222, 249,  81,  18,  70, 100,  96, 137, 125,   3, 211,  79,\n",
       "       117, 161, 210, 204, 102,  31,  84, 111, 124,  15,  13, 190, 179,\n",
       "       219, 166, 114, 139, 223, 216, 176,   5,  80,  75, 213,   0,  14,\n",
       "        95,  88,  10, 231, 212,  65,  83,  22, 230,  53,  82, 226,   9,\n",
       "       118, 250, 104, 101, 175,  93,  71, 158,   6,  77,  98,   7,  69,\n",
       "       129, 198,  73,  54,  58,  12, 224,  63, 147, 136,  90, 168,  72,\n",
       "       153, 113, 133, 164,  44, 163,  64,  91, 171,  24, 169, 199, 108,\n",
       "       201, 246, 157,   1, 132, 110,  20, 187, 251,  52, 123,  92, 120,\n",
       "        28,  86,  26, 215,  45, 119, 221,  43,  42,  47,  56,  39, 148,\n",
       "       240, 151, 109,  38,  32, 202, 185, 154,  78, 116, 155, 200, 126,\n",
       "       156,  30,  89, 245, 107, 197,  60, 182,  76, 106, 150,   8,  57,\n",
       "       146, 130, 173, 135,  41, 165, 167, 252, 241, 178, 247, 128, 194,\n",
       "       207, 203, 141, 144,  21, 180, 140, 233,  46,  40,  16, 174,  55,\n",
       "        34, 244, 152, 195, 115, 239, 122, 159, 134,  35,  59, 242,  25,\n",
       "       138, 186, 160, 218, 205, 238,  23, 177, 184, 191, 181, 145,  29,\n",
       "       142,  62, 121, 127,  36,  87, 192, 232, 188, 235, 162, 131,   2,\n",
       "        33,  61, 248, 227,  17, 237, 172,  27, 243, 193, 143, 234,  37,\n",
       "        19,  50,  49, 236, 149, 183])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[1].argsort()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('I have very little experience with canine generics and theriogenology.',\n",
       " 0.70914245)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 68\n",
    "all_responses[i], scores[0][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 1024)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_embeddings.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdbscan\n",
    "import numpy as np\n",
    " \n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=5, min_samples=1, prediction_data=True).fit(p_embeddings)\n",
    "soft_clusters = hdbscan.all_points_membership_vectors(clusterer)\n",
    "labels = [np.argmax(x) for x in soft_clusters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I don't know a lot about the canine breeder co...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One thing I do not understand is why we would ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I know that breeders are very passionate about...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I think there are likely breeders that do not ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have very little experience with the canine ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>that were helpful in understanding her role an...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Would have loved to be more involved with the ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>I think a mock show would be a great way for f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>For whelping and puppies if the timing works o...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>I think keeping in contact, maybe keeping the ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  labels\n",
       "0    I don't know a lot about the canine breeder co...       2\n",
       "1    One thing I do not understand is why we would ...       3\n",
       "2    I know that breeders are very passionate about...       3\n",
       "3    I think there are likely breeders that do not ...       3\n",
       "4    I have very little experience with the canine ...       2\n",
       "..                                                 ...     ...\n",
       "248  that were helpful in understanding her role an...       3\n",
       "249  Would have loved to be more involved with the ...       3\n",
       "250  I think a mock show would be a great way for f...       1\n",
       "251  For whelping and puppies if the timing works o...       3\n",
       "252  I think keeping in contact, maybe keeping the ...       3\n",
       "\n",
       "[253 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(zip(all_responses, labels), columns=['text', 'labels'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import collections\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def _is_stop_span(span):\n",
    "    doc = span.as_doc()\n",
    "    bools = [token.is_stop for token in doc]\n",
    "    \n",
    "    if any(bools):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def create_labels(df):\n",
    "    series_dict = {}\n",
    "\n",
    "    label_list = list(set(df.labels.unique()))\n",
    "    for label in tqdm(label_list): \n",
    "        spacy_docs = df.loc[df.labels == label].text.apply(nlp)\n",
    "        flat = [y for x in spacy_docs.apply(lambda x: [re.sub('[^\\w]','',chunk.text.lower()) for chunk in x.noun_chunks if not _is_stop_span(chunk)]).to_list() for y in x]\n",
    "        freq = collections.defaultdict(int)\n",
    "        for token in flat:\n",
    "            freq[token] += 1\n",
    "        freq = dict(freq)\n",
    "        tf = dict(sorted(freq.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "        idf = collections.defaultdict(int)\n",
    "        for term in tf:\n",
    "            for doc in spacy_docs:\n",
    "                if term in doc.text.lower():    \n",
    "                    idf[term] += 1\n",
    "        idf = dict(idf)\n",
    "        idf = dict(sorted(idf.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "        tfidf_dict = {}\n",
    "        for term, f in idf.items():\n",
    "            if tf[term] > 1:\n",
    "                tfidf_dict[term] = tf[term]*(math.log(len(spacy_docs)-f/f)+1) #smooth idf\n",
    "\n",
    "        tfidf_dict = dict(sorted(tfidf_dict.items(), key=lambda item: item[1], reverse=True)[:5])\n",
    "\n",
    "        key_string = ''\n",
    "        for i, term in enumerate(tfidf_dict):\n",
    "            if i < len(tfidf_dict)-1:\n",
    "                key_string += f'{term}; '\n",
    "            else:\n",
    "                key_string += f'{term}'\n",
    "        series_dict[f'label: {int(label)}'] = key_string\n",
    "\n",
    "    return pd.DataFrame.from_dict(series_dict, orient='index', columns=['topics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>label: 0</th>\n",
       "      <td>resources; therio; theriogenology; tufts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label: 1</th>\n",
       "      <td>dogs; people; terms; purpose; canine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label: 2</th>\n",
       "      <td>breeders; breeding; people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label: 3</th>\n",
       "      <td>breeders; breeding; people; veterinarians; inf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     topics\n",
       "label: 0           resources; therio; theriogenology; tufts\n",
       "label: 1               dogs; people; terms; purpose; canine\n",
       "label: 2                         breeders; breeding; people\n",
       "label: 3  breeders; breeding; people; veterinarians; inf..."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm = create_labels(df)\n",
    "tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'breeders; breeding; people; veterinarians; information'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm.topics.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('dla')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26c8c46588d5b2acb06918ee9447e16dc8aeea43f0cbd838ad3eb4fc9c314363"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
