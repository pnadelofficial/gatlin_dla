{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FlagEmbedding import FlagModel\n",
    "\n",
    "model = FlagModel(\"BAAI/bge-large-en\", \n",
    "    query_instruction_for_retrieval=\"Represent this sentence for searching relevant passages: \"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = ['conflicting', 'inexperience', 'assumption', 'appreciation', 'genetics', 'client relations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "consol_pre = pd.read_csv('./data/pre_consolidated.csv')\n",
    "sep_pre = consol_pre[['ID'] + list(consol_pre.columns[14:-2])]\n",
    "sep_pre_col_names = ['ID', 'Q14', 'Q15', 'Q16', 'Q18', 'Q19', 'Q20', 'Q21', 'Q22', 'Q23', 'Q24', 'Q25']\n",
    "sep_pre.columns = sep_pre_col_names\n",
    "\n",
    "consol_post = pd.read_csv('./data/post_consolidated.csv')\n",
    "sep_post = consol_post[['ID'] + list(consol_post.columns[14:-3])]\n",
    "sep_post_col_names = ['ID', 'Q15', 'Q16', 'Q17', 'Q18', 'Q19', 'Q20', 'Q21', 'Q22', 'Q23', 'Q24', 'Q25', 'Q26']\n",
    "sep_post.columns = sep_post_col_names\n",
    "\n",
    "pre_fr = sep_pre[['ID', 'Q20', 'Q21', 'Q22', 'Q23', 'Q24', 'Q25']]\n",
    "post_fr = sep_post[['ID', 'Q21', 'Q22', 'Q23', 'Q24', 'Q25', 'Q26']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import sent_tokenize\n",
    "\n",
    "all_responses = []\n",
    "for col in pre_fr.columns[1:]:\n",
    "    pre_sent = pre_fr[col].apply(sent_tokenize)\n",
    "    pre_sent = pre_sent.explode()\n",
    "    for fr in list(pre_sent):\n",
    "        all_responses.append(fr)\n",
    "\n",
    "for col in post_fr.columns[1:]:\n",
    "    post_sent = post_fr[col].apply(sent_tokenize)\n",
    "    post_sent = post_sent.explode()\n",
    "    for fr in list(post_sent):\n",
    "        all_responses.append(fr)\n",
    "\n",
    "len(all_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_embeddings = model.encode_queries(queries)\n",
    "p_embeddings = model.encode(all_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = q_embeddings @ p_embeddings.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 253)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 68,  74, 217, 229, 170,  51,  48, 206, 112,  85, 214,  66,  97,\n",
       "       196, 209, 189, 228,   4,  94,  99, 220, 225, 208,  67,  11, 103,\n",
       "       105, 222, 249,  81,  18,  70, 100,  96, 137, 125,   3, 211,  79,\n",
       "       117, 161, 210, 204, 102,  31,  84, 111, 124,  15,  13, 190, 179,\n",
       "       219, 166, 114, 139, 223, 216, 176,   5,  80,  75, 213,   0,  14,\n",
       "        95,  88,  10, 231, 212,  65,  83,  22, 230,  53,  82, 226,   9,\n",
       "       118, 250, 104, 101, 175,  93,  71, 158,   6,  77,  98,   7,  69,\n",
       "       129, 198,  73,  54,  58,  12, 224,  63, 147, 136,  90, 168,  72,\n",
       "       153, 113, 133, 164,  44, 163,  64,  91, 171,  24, 169, 199, 108,\n",
       "       201, 246, 157,   1, 132, 110,  20, 187, 251,  52, 123,  92, 120,\n",
       "        28,  86,  26, 215,  45, 119, 221,  43,  42,  47,  56,  39, 148,\n",
       "       240, 151, 109,  38,  32, 202, 185, 154,  78, 116, 155, 200, 126,\n",
       "       156,  30,  89, 245, 107, 197,  60, 182,  76, 106, 150,   8,  57,\n",
       "       146, 130, 173, 135,  41, 165, 167, 252, 241, 178, 247, 128, 194,\n",
       "       207, 203, 141, 144,  21, 180, 140, 233,  46,  40,  16, 174,  55,\n",
       "        34, 244, 152, 195, 115, 239, 122, 159, 134,  35,  59, 242,  25,\n",
       "       138, 186, 160, 218, 205, 238,  23, 177, 184, 191, 181, 145,  29,\n",
       "       142,  62, 121, 127,  36,  87, 192, 232, 188, 235, 162, 131,   2,\n",
       "        33,  61, 248, 227,  17, 237, 172,  27, 243, 193, 143, 234,  37,\n",
       "        19,  50,  49, 236, 149, 183])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[1].argsort()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('I have very little experience with canine generics and theriogenology.',\n",
       " 0.70914245)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 68\n",
    "all_responses[i], scores[0][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('dla')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26c8c46588d5b2acb06918ee9447e16dc8aeea43f0cbd838ad3eb4fc9c314363"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
